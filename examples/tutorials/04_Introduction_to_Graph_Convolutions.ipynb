{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "04_Introduction_to_Graph_Convolutions.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubFUlqz8cj1L",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial Part 4: Introduction to Graph Convolutions\n",
        "\n",
        "In the previous sections of the tutorial, we learned about `Dataset` and `Model` objects. We learned how to load some data into DeepChem from files on disk and also learned some basic facts about molecular data handling. We then dove into some basic deep learning architectures. However, until now, we stuck with vanilla deep learning architectures and didn't really consider how to handle deep architectures specifically engineered to work with life science data.\n",
        "\n",
        "In this tutorial, we'll change that by going a little deeper and learn about \"graph convolutions.\" These are one of the most powerful deep learning tools for working with molecular data. The reason for this is that molecules can be naturally viewed as graphs.\n",
        "\n",
        "![Molecular Graph](https://github.com/deepchem/deepchem/blob/master/examples/tutorials/basic_graphs.gif?raw=1)\n",
        "\n",
        "Note how standard chemical diagrams of the sort we're used to from high school lend themselves naturally to visualizing molecules as graphs. In the remainder of this tutorial, we'll dig into this relationship in significantly more detail. This will let us get an in-the guts understanding of how these systems work.\n",
        "\n",
        "## Colab\n",
        "\n",
        "This tutorial and the rest in this sequence are designed to be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/04_Introduction_to_Graph_Convolutions.ipynb)\n",
        "\n",
        "## Setup\n",
        "\n",
        "To run DeepChem within Colab, you'll need to run the following cell of installation commands. This will take about 5 minutes to run to completion and install your environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoCLxSnBcj1N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "d0555806-a13b-4522-c845-c36a7f910fca"
      },
      "source": [
        "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
        "import conda_installer\n",
        "conda_installer.install()\n",
        "!/root/miniconda/bin/conda info -e"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3490  100  3490    0     0  18177      0 --:--:-- --:--:-- --:--:-- 18082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "all packages are already installed\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                  *  /root/miniconda\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jv2cmnW91CF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "bd523c54-3038-4654-89ad-356ad1e207ca"
      },
      "source": [
        "!pip install --pre deepchem\n",
        "import deepchem\n",
        "deepchem.__version__"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepchem in /usr/local/lib/python3.6/dist-packages (2.4.0rc1.dev20200908171924)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.0.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from deepchem) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from deepchem) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->deepchem) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->deepchem) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0-rc1.dev'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEMqPVorcj1R",
        "colab_type": "text"
      },
      "source": [
        "Ok now that we have our environment installed, we can actually import the core `GraphConvModel` that we'll use through this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph78CIgAcj1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import deepchem as dc\n",
        "from deepchem.models.graph_models import GraphConvModel"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX2erW0ncj1W",
        "colab_type": "text"
      },
      "source": [
        "Now, let's use the MoleculeNet suite  to load the Tox21 dataset. We need to make sure to process the data in a way that graph convolutional networks can use for that, we make sure to set the featurizer option to 'GraphConv'. The MoleculeNet call will return a training set, a validation set, and a test set for us to use. The call also returns `transformers`, a list of data transformations that were applied to preprocess the dataset. (Most deep networks are quite finicky and require a set of data transformations to ensure that training proceeds stably.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMi2V8Jncj1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "56ab5eb6-07be-4d8f-c19b-88d1f73f2f46"
      },
      "source": [
        "# Load Tox21 dataset\n",
        "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21(featurizer='GraphConv', reload=False)\n",
        "train_dataset, valid_dataset, test_dataset = tox21_datasets"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "smiles_field is deprecated and will be removed in a future version of DeepChem.Use feature_field instead.\n",
            "/usr/local/lib/python3.6/dist-packages/deepchem/data/data_loader.py:162: FutureWarning: featurize() is deprecated and has been renamed to create_dataset().featurize() will be removed in DeepChem 3.0\n",
            "  \"featurize() will be removed in DeepChem 3.0\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfMW0Y4Kcj1Z",
        "colab_type": "text"
      },
      "source": [
        "Let's now train a graph convolutional network on this dataset. DeepChem has the class `GraphConvModel` that wraps a standard graph convolutional architecture underneath the hood for user convenience. Let's instantiate an object of this class and train it on our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9n3jTNHcj1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "2caab2e5-5e5a-4f97-a440-753692341d35"
      },
      "source": [
        "n_tasks = len(tox21_tasks)\n",
        "model = GraphConvModel(n_tasks, batch_size=50, mode='classification')\n",
        "\n",
        "num_epochs = 10\n",
        "losses = []\n",
        "for i in range(num_epochs):\n",
        " loss = model.fit(train_dataset, nb_epoch=1)\n",
        " print(\"Epoch %d loss: %f\" % (i, loss))\n",
        " losses.append(loss)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 loss: 0.196743\n",
            "Epoch 1 loss: 0.179927\n",
            "Epoch 2 loss: 0.167149\n",
            "Epoch 3 loss: 0.131064\n",
            "Epoch 4 loss: 0.155983\n",
            "Epoch 5 loss: 0.152273\n",
            "Epoch 6 loss: 0.144918\n",
            "Epoch 7 loss: 0.132300\n",
            "Epoch 8 loss: 0.140850\n",
            "Epoch 9 loss: 0.137812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozuyj_umcj1c",
        "colab_type": "text"
      },
      "source": [
        "Let's plot these losses so we can take a look at how the loss changes over the process of training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbDXnYs7cj1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "cefc40a9-15c4-4d02-b4a2-81009a35c042"
      },
      "source": [
        "import matplotlib.pyplot as plot\n",
        "\n",
        "plot.ylabel(\"Loss\")\n",
        "plot.xlabel(\"Epoch\")\n",
        "x = range(num_epochs)\n",
        "y = losses\n",
        "plot.scatter(x, y)\n",
        "plot.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWu0lEQVR4nO3dcZBdZ33e8e/DWg6LCcgJmky0srGTOAJTGwuuTQjBFBIiMWls1THBDmRwhxlPSZ1AU6u12pnO4LRjgpIMIXFaK5S0mUI81BUatYXKlDiQToBqZWEL2VWqqkbWmgQxRDGEDUjyr3/cK3m1OpLuWnv2rPZ+PzN3dM97zrnz0x1pnz3ve877pqqQJGm253VdgCRpcTIgJEmNDAhJUiMDQpLUyICQJDUyICRJjVoNiCTrkuxNsi/JXQ37fzXJY0keTfKZJC+dse+dSf7P4PXONuuUJJ0qbT0HkWQM+HPgzcBBYAdwa1U9NuOYNwJfrKpvJ3k38Her6m1Jvg+YBHpAATuBV1fVX7VSrCTpFG1eQVwH7Kuq/VX1XeB+4MaZB1TVQ1X17cHmF4BVg/drgU9X1TcGofBpYF2LtUqSZrmgxc+eAJ6csX0QeM0Zjn8X8KkznDsx+4QktwO3A1x00UWvftnLXnYu9UrSyNm5c+fXq2pF0742A2JoSd5BvzvpDXM5r6o2A5sBer1eTU5OtlCdJC1dSb5yun1tdjFNAZfM2F41aDtJkp8C/gVwQ1V9Zy7nSpLa02ZA7ACuSHJ5kguBW4BtMw9Isga4j344fG3Gru3ATye5OMnFwE8P2iRJC6S1LqaqOprkDvo/2MeAj1TVniR3A5NVtQ3YBLwQ+E9JAA5U1Q1V9Y0kv0Y/ZADurqpvtFWrJOlUrd3mutAcg5CkuUuys6p6Tft8klqS1GhR3MXUpa27pti0fS9PHZ5m5fJxNqxdzfo1p9xRK0kjZ6QDYuuuKTZu2c30kWMATB2eZuOW3QCGhKSRN9JdTJu27z0RDsdNHznGpu17O6pIkhaPkQ6Ipw5Pz6ldkkbJSAfEyuXjc2qXpFEy0gGxYe1qxpeNndQ2vmyMDWtXd1SRJC0eIz1IfXwg2ruYJOlUIx0Q0A8JA0GSTjXSXUySpNMzICRJjQwISVIjA0KS1MiAkCQ1MiAkSY0MCElSIwNCktTIgJAkNTIgJEmNDAhJUiMDQpLUqNWASLIuyd4k+5Lc1bD/+iQPJzma5OZZ+349yZcHr7e1Wack6VStBUSSMeBe4C3AlcCtSa6cddgB4DbgY7PO/RngVcA1wGuAO5O8qK1aJUmnavMK4jpgX1Xtr6rvAvcDN848oKqeqKpHgWdmnXsl8LmqOlpVfwM8CqxrsVZJ0ixtBsQE8OSM7YODtmE8AqxL8oIkLwHeCFwyz/VJks5gUS4YVFUPJrkW+DPgEPB54Njs45LcDtwOcOmlly5ojZK01LV5BTHFyb/1rxq0DaWq/nVVXVNVbwYC/HnDMZurqldVvRUrVpxzwZKkZ7UZEDuAK5JcnuRC4BZg2zAnJhlL8v2D91cDVwMPtlapJOkUrXUxVdXRJHcA24Ex4CNVtSfJ3cBkVW0bdCN9ArgY+Nkk76uqVwDLgD9NAvA08I6qOtpWrZKkU7U6BlFVnwQ+OavtX854v4N+19Ps8/6W/p1MkqSO+CS1JKmRASFJamRASJIaGRCSpEYGhCSpkQEhSWpkQEiSGhkQkqRGBoQkqZEBIUlqZEBIkhoZEJKkRgaEJKmRASFJamRASJIaGRCSpEYGhCSpkQEhSWpkQEiSGhkQkqRGBoQkqVGrAZFkXZK9SfYluath//VJHk5yNMnNs/Z9IMmeJI8n+VCStFmrJOlkF7T1wUnGgHuBNwMHgR1JtlXVYzMOOwDcBtw569wfB14HXD1o+p/AG4A/aaveLm3dNcWm7Xt56vA0K5ePs2Htatavmei6LEkjrrWAAK4D9lXVfoAk9wM3AicCoqqeGOx7Zta5BTwfuBAIsAz4yxZr7czWXVNs3LKb6SPHAJg6PM3GLbsBDAlJnWqzi2kCeHLG9sFB21lV1eeBh4CvDl7bq+rxea9wEdi0fe+JcDhu+sgxNm3f21FFktS3KAepk/wI8HJgFf1QeVOS1zccd3uSySSThw4dWugy58VTh6fn1C5JC6XNgJgCLpmxvWrQNoy/D3yhqr5VVd8CPgW8dvZBVbW5qnpV1VuxYsU5F9yFlcvH59QuSQulzYDYAVyR5PIkFwK3ANuGPPcA8IYkFyRZRn+Aekl2MW1Yu5rxZWMntY0vG2PD2tUdVSRJfa0FRFUdBe4AttP/4f7xqtqT5O4kNwAkuTbJQeCtwH1J9gxOfwD4v8Bu4BHgkar6L23V2qX1aya456armFg+ToCJ5ePcc9NVDlBL6lyqqusa5kWv16vJycmuy5Ck80qSnVXVa9q3KAepJUndMyAkSY0MCElSIwNCktTIgJAkNTIgJEmNDAhJUiMDQpLUyICQJDUyICRJjQwISVIjA0KS1MiAkCQ1MiAkSY0MCElSIwNCktTIgJAkNTIgJEmNDAhJUiMDQpLUyICQJDVqNSCSrEuyN8m+JHc17L8+ycNJjia5eUb7G5N8acbrb5Osb7NWSdLJLmjrg5OMAfcCbwYOAjuSbKuqx2YcdgC4Dbhz5rlV9RBwzeBzvg/YBzzYVq2SpFO1FhDAdcC+qtoPkOR+4EbgREBU1RODfc+c4XNuBj5VVd9ur1RJ0mxtdjFNAE/O2D44aJurW4A/mpeKJElDW9SD1El+ELgK2H6a/bcnmUwyeejQoYUtTpKWuDYDYgq4ZMb2qkHbXPw88ImqOtK0s6o2V1WvqnorVqx4jmVKkpq0GRA7gCuSXJ7kQvpdRdvm+Bm3YveSJHWitYCoqqPAHfS7hx4HPl5Ve5LcneQGgCTXJjkIvBW4L8me4+cnuYz+Fchn26pRknR6qaqua5gXvV6vJicnuy5Dks4rSXZWVa9pX5u3ueo8s3XXFJu27+Wpw9OsXD7OhrWrWb/mudx4JmkpMCAE9MNh45bdTB85BsDU4Wk2btkNYEhII2pR3+aqhbNp+94T4XDc9JFjbNq+t6OKJHXNgBAATx2enlO7pKXPgBAAK5ePz6ld0tI3VEAkuSjJ8wbvfzTJDUmWtVuaFtKGtasZXzZ2Utv4sjE2rF3dUUWSujbsFcTngOcnmaA/q+ovAv++raK08NavmeCem65iYvk4ASaWj3PPTVc5QC2NsGHvYkpVfTvJu4Dfq6oPJPlSm4Vp4a1fM2EgSDph2CuIJHkt8Hbgvw3axs5wvCTpPDdsQLwX2Eh/4rw9SX4IeKi9siRJXRuqi6mqPstgTqTBYPXXq+pX2ixMktStYe9i+liSFyW5CPgy8FiSDe2WJknq0rBdTFdW1dPAeuBTwOX072SSJC1RwwbEssFzD+uBbYMFfJbGNLCSpEbDBsR9wBPARcDnkrwUeLqtoiRJ3Rt2kPpDwIdmNH0lyRvbKUmStBgMO0j94iS/lWRy8PpN+lcTkqQlatgupo8A3wR+fvB6GviDtoqSJHVv2Kk2friqfm7G9vucakOSlrZhryCmk/zE8Y0krwNcKECSlrBhryD+IfCHSV482P4r4J3tlCRJWgyGvYvpEeCVSV402H46yXuBR9ssTpLUnTmtKFdVTw+eqAb41bMdn2Rdkr1J9iW5q2H/9UkeTnI0yc2z9l2a5MEkjyd5LMllc6lVknRuzmXJ0ZxxZzIG3Au8BbgSuDXJlbMOOwDcBnys4SP+ENhUVS8HrgO+dg61SpLmaNgxiCZnm2rjOmBfVe0HSHI/cCPw2IkPqHpisO+ZmScOguSCqvr04LhvnUOdkqTn4IwBkeSbNAdBgLOtZj8BPDlj+yDwmiHr+lHgcJIt9CcG/B/AXVV1bFZ9twO3A1x66aVDfrQkaRhn7GKqqu+tqhc1vL63qs7l6uNsLgBeD9wJXAv8EP2uqNn1ba6qXlX1VqxY0WI5kjR6zmUM4mymgEtmbK8atA3jIPClqtpfVUeBrcCr5rk+SdIZtBkQO4Arklye5ELgFmDbHM5dnuT4ZcGbmDF2IUlqX2sBMfjN/w5gO/A48PHBetZ3J7kBIMm1SQ4CbwXuS7JncO4x+t1Ln0mym/6Yx++3Vask6VSpWhrr/vR6vZqcnOy6DEk6ryTZWVW9pn1tdjFJks5jBoQkqZEBIUlq1OazDNJ5beuuKTZt38tTh6dZuXycDWtXs37NRNdlSQvGgJAabN01xcYtu5k+0n94f+rwNBu37AYwJDQy7GKSGmzavvdEOBw3feQYm7bv7agiaeEZEFKDpw43L5h4unZpKTIgpAYrlzfPRXm6dmkpMiCkBhvWrmZ82dhJbePLxtiwdnVHFUkLz0FqqcHxgWjvYtIoMyCk01i/ZsJA0Eizi0mS1MiAkCQ1MiAkSY0cg5AWOaf8UFcMCGkRc8oPdckuJmkRc8oPdcmAkBYxp/xQlwwIaRFzyg91yYCQFjGn/FCXHKSWFjGn/FCXWg2IJOuA3wbGgA9X1ftn7b8e+CBwNXBLVT0wY98xYPdg80BV3dBmrdJi5ZQf6kprAZFkDLgXeDNwENiRZFtVPTbjsAPAbcCdDR8xXVXXtFWfJOnM2ryCuA7YV1X7AZLcD9wInAiIqnpisO+ZFuuQJD0HbQ5STwBPztg+OGgb1vOTTCb5QpL1TQckuX1wzOShQ4fOpVZJ0iyL+S6ml1ZVD/gF4INJfnj2AVW1uap6VdVbsWLFwlcoSUtYmwExBVwyY3vVoG0oVTU1+HM/8CfAmvksTpJ0Zm0GxA7giiSXJ7kQuAXYNsyJSS5O8j2D9y8BXseMsQtJUvtaC4iqOgrcAWwHHgc+XlV7ktyd5AaAJNcmOQi8FbgvyZ7B6S8HJpM8AjwEvH/W3U+SpJalqrquYV70er2anJzsugxJOq8k2TkY7z3FYh6kliR1yICQJDUyICRJjQwISVIjA0KS1MiAkCQ1cj0ISUPZumvKdSlGjAEh6ay27ppi45bdTB85BsDU4Wk2bukv12JILF12MUk6q03b954Ih+Omjxxj0/a9HVWkhWBASDqrpw5Pz6ldS4MBIemsVi4fn1O7lgYDQtJZbVi7mvFlYye1jS8bY8Pa1R1VpIXgILWkszo+EO1dTKPFgJA0lPVrJgyEEWMXkySpkQEhSWpkQEiSGhkQkqRGDlJL0hyNyrxUBoQkzcEozUtlF5MkzcEozUvVakAkWZdkb5J9Se5q2H99koeTHE1yc8P+FyU5mOR326xTkoY1SvNStRYQScaAe4G3AFcCtya5ctZhB4DbgI+d5mN+DfhcWzVK0lyN0rxUbV5BXAfsq6r9VfVd4H7gxpkHVNUTVfUo8Mzsk5O8GvgB4MEWa5SkORmleanaDIgJ4MkZ2wcHbWeV5HnAbwJ3nuW425NMJpk8dOjQcy5Ukoa1fs0E99x0FRPLxwkwsXyce266askNUMPivYvpl4BPVtXBJKc9qKo2A5sBer1eLVBtkkbcqMxL1WZATAGXzNheNWgbxmuB1yf5JeCFwIVJvlVVpwx0S5La0WZA7ACuSHI5/WC4BfiFYU6sqrcff5/kNqBnOEjSwmotIKrqaJI7gO3AGPCRqtqT5G5gsqq2JbkW+ARwMfCzSd5XVa9oqyZJWkrafqI7VUuj677X69Xk5GTXZUjSgpj9RDf076aa64B5kp1V1Wva55PUknQeWognug0ISToPLcQT3QaEJJ2HFuKJbgNCks5DC/FE92J9UE6SdAbHB6LbvIvJgJCk81TbT3TbxSRJamRASJIaGRCSpEYGhCSpkQEhSWpkQEiSGhkQkqRGBoQkqZEPykk6b7S9/oFOZkBIOi/MXv9g6vA0G7fsBjAkWmIXk6TzwkKsf6CTGRCSzgsLsf6BTmYXkxYd+5nVZOXycaYawmA+1z/QybyC0KJyvJ956vA0xbP9zFt3TXVdmjq2EOsf6GQGhBYV+5l1OuvXTHDPTVcxsXycABPLx7nnpqu8umxRq11MSdYBvw2MAR+uqvfP2n898EHgauCWqnpg0P5S4BP0A2wZ8DtV9W/brFWLg/3MOpO21z/QyVq7gkgyBtwLvAW4Erg1yZWzDjsA3AZ8bFb7V4HXVtU1wGuAu5KsbKtWLR4Lsc6upOG02cV0HbCvqvZX1XeB+4EbZx5QVU9U1aPAM7Pav1tV3xlsfk/LdWoRsZ9ZWjza/ME7ATw5Y/vgoG0oSS5J8ujgM369qp5qOOb2JJNJJg8dOnTOBat79jNLi8eivc21qp4Erh50LW1N8kBV/eWsYzYDmwF6vV51UKZaYD+ztDi0eQUxBVwyY3vVoG1OBlcOXwZeP091SZKG0GZA7ACuSHJ5kguBW4Btw5yYZFWS8cH7i4GfALzPUZIWUGsBUVVHgTuA7cDjwMerak+Su5PcAJDk2iQHgbcC9yXZMzj95cAXkzwCfBb4jara3VatkqRTpWppdN33er2anJzsugxJOq8k2VlVvaZ93j4qSWq0ZK4gkhwCvnIOH/ES4OvzVM75zu/iZH4fJ/P7eNZS+C5eWlUrmnYsmYA4V0kmT3eZNWr8Lk7m93Eyv49nLfXvwi4mSVIjA0KS1MiAeNbmrgtYRPwuTub3cTK/j2ct6e/CMQhJUiOvICRJjQwISVKjkQ+IJOuS7E2yL8ldXdfTpcEU6w8leSzJniTv6bqmriUZS7IryX/tupauJVme5IEk/zvJ40le23VNXUryjwf/T76c5I+SPL/rmubbSAfEkKvejZKjwD+pqiuBHwP+0Yh/HwDvoT+XmPrLB//3qnoZ8EpG+HtJMgH8CtCrqr9Df1nlW7qtav6NdEAwxKp3o6SqvlpVDw/ef5P+D4CRXZghySrgZ4APd11L15K8GLge+HdwYtXHw91W1bkLgPEkFwAvAE5Z1Ox8N+oBcU6r3i1lSS4D1gBf7LaSTn0Q+KfMWhJ3RF0OHAL+YNDl9uEkF3VdVFeqagr4DeAA8FXgr6vqwW6rmn+jHhBqkOSFwH8G3ltVT3ddTxeS/D3ga1W1s+taFokLgFcB/6aq1gB/A4zsmN1gnZob6QfnSuCiJO/otqr5N+oBMS+r3i0lSZbRD4ePVtWWruvp0OuAG5I8Qb/r8U1J/mO3JXXqIHCwqo5fUT5APzBG1U8B/6+qDlXVEWAL8OMd1zTvRj0gnvOqd0tRktDvY368qn6r63q6VFUbq2pVVV1G/9/FH1fVkvsNcVhV9RfAk0lWD5p+Enisw5K6dgD4sSQvGPy/+UmW4KD9BV0X0KWqOprk+Kp3Y8BHqmrPWU5byl4H/CKwO8mXBm3/vKo+2WFNWjx+Gfjo4Jep/cA/6LiezlTVF5M8ADxM/+6/XSzBaTecakOS1GjUu5gkSadhQEiSGhkQkqRGBoQkqZEBIUlqZEBIc5DkWJIvzXjN29PESS5L8uX5+jzpXI30cxDSczBdVdd0XYS0ELyCkOZBkieSfCDJ7iT/K8mPDNovS/LHSR5N8pkklw7afyDJJ5I8Mngdn6ZhLMnvD9YZeDDJeGd/KY08A0Kam/FZXUxvm7Hvr6vqKuB36c8EC/A7wH+oqquBjwIfGrR/CPhsVb2S/pxGx5/gvwK4t6peARwGfq7lv490Wj5JLc1Bkm9V1Qsb2p8A3lRV+wcTHv5FVX1/kq8DP1hVRwbtX62qlyQ5BKyqqu/M+IzLgE9X1RWD7X8GLKuqf9X+30w6lVcQ0vyp07yfi+/MeH8MxwnVIQNCmj9vm/Hn5wfv/4xnl6J8O/Cng/efAd4NJ9a9fvFCFSkNy99OpLkZnzHTLfTXaD5+q+vFSR6lfxVw66Dtl+mvwraB/opsx2dAfQ+wOcm76F8pvJv+ymTSouEYhDQPBmMQvar6ete1SPPFLiZJUiOvICRJjbyCkCQ1MiAkSY0MCElSIwNCktTIgJAkNfr/c9AnRAHm5z0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDDroutEcj1g",
        "colab_type": "text"
      },
      "source": [
        "We see that the losses fall nicely and give us stable learning.\n",
        "\n",
        "Let's try to evaluate the performance of the model we've trained. For this, we need to define a metric, a measure of model performance. `dc.metrics` holds a collection of metrics already. For this dataset, it is standard to use the ROC-AUC score, the area under the receiver operating characteristic curve (which measures the tradeoff between precision and recall). Luckily, the ROC-AUC score is already available in DeepChem. \n",
        "\n",
        "To measure the performance of the model under this metric, we can use the convenience function `model.evaluate()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeX-9RNWcj1h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "642d3f81-33de-46bb-fc7a-8b5edda99881"
      },
      "source": [
        "import numpy as np\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
        "\n",
        "print(\"Evaluating model\")\n",
        "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
        "print(\"Training ROC-AUC Score: %f\" % train_scores[\"mean-roc_auc_score\"])\n",
        "valid_scores = model.evaluate(valid_dataset, [metric], transformers)\n",
        "print(\"Validation ROC-AUC Score: %f\" % valid_scores[\"mean-roc_auc_score\"])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.887089\n",
            "Validation ROC-AUC Score: 0.778292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-LBxrKN6CMs",
        "colab_type": "text"
      },
      "source": [
        "What's going on under the hood? Could we build GraphConvModel ourselves? Of course! Let's first understand the inputs to the model and generate the relevant data.\n",
        "\n",
        "Conceptually, graph convolutions just require the structure of the molecule in question and a vector of features for every atom that describes the local chemical environment.\n",
        "\n",
        "`atom_features` holds a feature vector of length 75 for each atom. The other inputs are required to support minibatching in TensorFlow. `degree_slice` is an indexing convenience that makes it easy to locate atoms from all molecules with a given degree. `membership` determines the membership of atoms in molecules (atom `i` belongs to molecule membership[i]). `deg_adjs` is a list that contains adjacency lists grouped by atom degree. For more details, check out the [code](https://github.com/deepchem/deepchem/blob/master/deepchem/feat/mol_graphs.py).\n",
        "\n",
        "Following code creates a Python generator that given a batch of data generates the lists of inputs, labels, and weights whose values are Numpy arrays. We will use for this step of training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-cPAG0I8Tc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deepchem.metrics import to_one_hot\n",
        "from deepchem.feat.mol_graphs import ConvMol\n",
        "\n",
        "def data_generator(dataset, predict=False, pad_batches=True):\n",
        "  for ind, (X_b, y_b, w_b, ids_b) in enumerate(\n",
        "      dataset.iterbatches(\n",
        "          batch_size, pad_batches=pad_batches, deterministic=True)):\n",
        "    multiConvMol = ConvMol.agglomerate_mols(X_b)\n",
        "    inputs = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
        "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
        "      inputs.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
        "    labels = [to_one_hot(y_b.flatten(), 2).reshape(-1, n_tasks, 2)]\n",
        "    weights = [w_b]\n",
        "    yield (inputs, labels, weights)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz43oG9rcj1j",
        "colab_type": "text"
      },
      "source": [
        "Now let's create the `Keras model` and [keras layers](https://keras.io/api/layers/) of the model.\n",
        "\n",
        "DeepChem already provides wrapper around keras layers to build graph convolutional model. We are going to apply following layers from DeepChem.\n",
        "\n",
        "-  `GraphConv` layer: This layer implements the graph convolution. The graph convolution combines per-node feature vectures in a nonlinear fashion with the feature vectors for neighboring nodes.  This \"blends\" information in local neighborhoods of a graph.\n",
        "\n",
        "- `GraphPool` layer: This layer does a max-pooling over the feature vectors of atoms in a neighborhood. You can think of this layer as analogous to a max-pooling layer for 2D convolutions but which operates on graphs instead. \n",
        "\n",
        "- `GraphGather`: Many graph convolutional networks manipulate feature vectors per graph-node. For a molecule for example, each node might represent an atom, and the network would manipulate atomic feature vectors that summarize the local chemistry of the atom. However, at the end of the application, we will likely want to work with a molecule level feature representation. This layer creates a graph level feature vector by combining all the node-level feature vectors.\n",
        "\n",
        "Apart from this we are going to apply standard neural network layers such as [Dense](https://keras.io/api/layers/core_layers/dense/), [BatchNormalization](https://keras.io/api/layers/normalization_layers/batch_normalization/) and [Softmax](https://keras.io/api/layers/activation_layers/softmax/) layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71_E0CAUcj1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "class MyKerasModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyKerasModel, self).__init__()\n",
        "    self.gc1 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
        "    self.batch_norm1 = layers.BatchNormalization()\n",
        "    self.gp1 = GraphPool()\n",
        "\n",
        "    self.gc2 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
        "    self.batch_norm2 = layers.BatchNormalization()\n",
        "    self.gp2 = GraphPool()\n",
        "\n",
        "    self.dense1 = layers.Dense(256, activation=tf.nn.tanh)\n",
        "    self.batch_norm3 = layers.BatchNormalization()\n",
        "    self.readout = GraphGather(batch_size=batch_size, activation_fn=tf.nn.tanh)\n",
        "\n",
        "    self.dense2 = layers.Dense(n_tasks*2)\n",
        "    self.logits = layers.Reshape((n_tasks, 2))\n",
        "    self.softmax = layers.Softmax()\n",
        "\n",
        "  def call(self, inputs):\n",
        "    gc1_output = self.gc1(inputs)\n",
        "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
        "    gp1_output = self.gp1([batch_norm1_output] + inputs[1:])\n",
        "\n",
        "    gc2_output = self.gc2([gp1_output] + inputs[1:])\n",
        "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
        "    gp2_output = self.gp2([batch_norm2_output] + inputs[1:])\n",
        "\n",
        "    dense1_output = self.dense1(gp2_output)\n",
        "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
        "    readout_output = self.readout([batch_norm3_output] + inputs[1:])\n",
        "\n",
        "    logits_output = self.logits(self.dense2(readout_output))\n",
        "    return self.softmax(logits_output)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC20PZiccj1p",
        "colab_type": "text"
      },
      "source": [
        "Let's now create the DeepChem model which will be a wrapper around the keras model that we just created. \n",
        "\n",
        "DeepChem models provide useful utilities on top of the keras model. We will also specify the loss function so the model know the objective to minimize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31Wr0t2zcj1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = dc.models.losses.CategoricalCrossEntropy()\n",
        "model = dc.models.KerasModel(MyKerasModel(), loss=loss)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSTbjm9Hcj1v",
        "colab_type": "text"
      },
      "source": [
        "Now, we can train the model using `fit_generator(generator)` which will use the generator we've defined to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59WW4rhwcj1w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "660ecb20-a2f4-4ae5-e0c8-bc72e309ee72"
      },
      "source": [
        "num_epochs = 10\n",
        "losses = []\n",
        "for i in range(num_epochs):\n",
        "  loss = model.fit_generator(data_generator(train_dataset))\n",
        "  print(\"Epoch %d loss: %f\" % (i, loss))\n",
        "  losses.append(loss)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 loss: 0.189484\n",
            "Epoch 1 loss: 0.181750\n",
            "Epoch 2 loss: 0.173860\n",
            "Epoch 3 loss: 0.129647\n",
            "Epoch 4 loss: 0.159841\n",
            "Epoch 5 loss: 0.155564\n",
            "Epoch 6 loss: 0.150758\n",
            "Epoch 7 loss: 0.139902\n",
            "Epoch 8 loss: 0.140270\n",
            "Epoch 9 loss: 0.135996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KKBu75ccj1z",
        "colab_type": "text"
      },
      "source": [
        "Let's now plot these losses and take a quick look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaPi5y8icj11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1b87260f-adfa-4b19-bb3a-55d6ce3565e4"
      },
      "source": [
        "plot.title(\"Keras Version\")\n",
        "plot.ylabel(\"Loss\")\n",
        "plot.xlabel(\"Epoch\")\n",
        "x = range(num_epochs)\n",
        "y = losses\n",
        "plot.scatter(x, y)\n",
        "plot.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skrL9YEEcj13",
        "colab_type": "text"
      },
      "source": [
        "Now that we have trained our graph convolutional method, let's evaluate its performance. We again have to use our defined generator to evaluate model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "f3prNsgGcj14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "dc95fbba-f5bf-4f7b-8d56-efdc37345d80"
      },
      "source": [
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
        "\n",
        "def reshape_y_pred(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    GraphConv always pads batches, so we need to remove the predictions\n",
        "    for the padding samples.  Also, it outputs two values for each task\n",
        "    (probabilities of positive and negative), but we only want the positive\n",
        "    probability.\n",
        "    \"\"\"\n",
        "    n_samples = len(y_true)\n",
        "    return y_pred[:n_samples, :, 1]\n",
        "    \n",
        "\n",
        "print(\"Evaluating model\")\n",
        "train_predictions = model.predict_on_generator(data_generator(train_dataset, predict=True))\n",
        "train_predictions = reshape_y_pred(train_dataset.y, train_predictions)\n",
        "train_scores = metric.compute_metric(train_dataset.y, train_predictions, train_dataset.w)\n",
        "print(\"Training ROC-AUC Score: %f\" % train_scores)\n",
        "\n",
        "valid_predictions = model.predict_on_generator(data_generator(valid_dataset, predict=True))\n",
        "valid_predictions = reshape_y_pred(valid_dataset.y, valid_predictions)\n",
        "valid_scores = metric.compute_metric(valid_dataset.y, valid_predictions, valid_dataset.w)\n",
        "print(\"Valid ROC-AUC Score: %f\" % valid_scores)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.776245\n",
            "Valid ROC-AUC Score: 0.702370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvOYgj52cj16",
        "colab_type": "text"
      },
      "source": [
        "Success! The model we've constructed behaves nearly identically to `GraphConvModel`. If you're looking to build your own custom models, you can follow the example we've provided here to do so. We hope to see exciting constructions from your end soon!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "j1FrVn88cj17",
        "colab_type": "text"
      },
      "source": [
        "# Congratulations! Time to join the Community!\n",
        "\n",
        "Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n",
        "\n",
        "## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)\n",
        "This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.\n",
        "\n",
        "## Join the DeepChem Gitter\n",
        "The DeepChem [Gitter](https://gitter.im/deepchem/Lobby) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!"
      ]
    }
  ]
}